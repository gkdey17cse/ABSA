{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aspect-Based Sentiment Analysis with LSTM Local Context Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'RNN_Local_Context'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m \u001b[38;5;66;03m#Import the json modul\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m \u001b[38;5;66;03m#Import pickle modul\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRNN_Local_Context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RNNClassifierWithAttention\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m \n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'RNN_Local_Context'"
     ]
    }
   ],
   "source": [
    "import json #Import the json modul\n",
    "import pickle #Import pickle modul\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# To Load pre-trained embeddings\n",
    "with open(\"fasttext_embeddings_25.pkl\", \"rb\") as f:\n",
    "    fasttext_embeddings = pickle.load(f)\n",
    "\n",
    "\n",
    "# To Extract local context (left and right neighbors of the aspect term)\n",
    "def extract_local_context(entry):\n",
    "    aspect_index = entry[\"index\"]  # the Position of the aspect term in the sentence\n",
    "    tokens = entry[\"tokens\"]  # the List of tokens in the sentence\n",
    "\n",
    "    # will Get the left and right neighbors\n",
    "    left_context = [tokens[aspect_index - 1]] if aspect_index > 0 else []\n",
    "    right_context = [tokens[aspect_index + 1]] if aspect_index < len(tokens) - 1 else []\n",
    "\n",
    "    # Combine left and right context\n",
    "    context_tokens = left_context + right_context\n",
    "\n",
    "    # Convert tokens to embeddings (use zero vector if token not in embeddings)\n",
    "    context_embeddings = [\n",
    "        fasttext_embeddings.get(token, np.zeros(25)) for token in context_tokens\n",
    "    ]\n",
    "\n",
    "    # Pad context to ensure it has exactly 2 embeddings (left + right)\n",
    "    while len(context_embeddings) < 2:\n",
    "        context_embeddings.append(np.zeros(25))\n",
    "\n",
    "    # Get embedding for the aspect term\n",
    "    aspect_embedding = fasttext_embeddings.get(entry[\"aspect_terms\"][0], np.zeros(25))\n",
    "\n",
    "    return np.array(context_embeddings), np.array(aspect_embedding)\n",
    "\n",
    "\n",
    "# Function to process the dataset\n",
    "def process_data(json_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Map sentiment labels to integers\n",
    "    label_mapping = {\"positive\": 0, \"negative\": 1, \"neutral\": 2, \"conflict\": 3}\n",
    "\n",
    "    X_context, X_aspect, y = [], [], []\n",
    "    for entry in data:\n",
    "        context, aspect = extract_local_context(entry)\n",
    "        X_context.append(context)\n",
    "        X_aspect.append(aspect)\n",
    "        y.append(label_mapping[entry[\"polarity\"]])\n",
    "\n",
    "    return (\n",
    "        np.array(X_context, dtype=np.float32),\n",
    "        np.array(X_aspect, dtype=np.float32),\n",
    "        np.array(y),\n",
    "    )\n",
    "\n",
    "\n",
    "# Load training and validation data\n",
    "X_train_context, X_train_aspect, y_train = process_data(\"train_task_2.json\")\n",
    "X_val_context, X_val_aspect, y_val = process_data(\"val_task_2.json\")\n",
    "\n",
    "# Convert data to PyTorch tensors and create DataLoaders\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train_context), torch.tensor(y_train, dtype=torch.long)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(X_val_context), torch.tensor(y_val, dtype=torch.long)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Define the Attention Mechanism\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Linear(\n",
    "            hidden_dim, 1\n",
    "        )  # Linear layer to compute attention scores\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, hidden_dim)\n",
    "        attention_scores = self.attention(x)  # Compute attention scores\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)  # Apply softmax\n",
    "        context_vector = torch.sum(attention_weights * x, dim=1)  # Weighted sum\n",
    "        return context_vector\n",
    "\n",
    "\n",
    "# Define the RNN Model with Attention\n",
    "class RNNClassifierWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim=25, hidden_dim=64, output_dim=4):\n",
    "        super(RNNClassifierWithAttention, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)  # RNN layer\n",
    "        self.attention = Attention(hidden_dim)  # Attention layer\n",
    "        self.fc1 = nn.Linear(hidden_dim, 32)  # Fully connected layer\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.fc2 = nn.Linear(32, output_dim)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        rnn_out, _ = self.rnn(\n",
    "            x\n",
    "        )  # RNN output: (batch_size, sequence_length, hidden_dim)\n",
    "        attention_out = self.attention(rnn_out)  # Apply attention\n",
    "        out = self.fc1(attention_out)  # Pass through fully connected layer\n",
    "        out = self.relu(out)  # Apply ReLU\n",
    "        out = self.fc2(out)  # Final output\n",
    "        return out\n",
    "\n",
    "\n",
    "# Set up device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = RNNClassifierWithAttention().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Optimizer\n",
    "\n",
    "# Lists to store training and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):  # Train for 20 epochs\n",
    "    model.train()  # Set model to training mode\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Training phase\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # Move data to device\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(batch_X)  # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        total_train_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "    # Calculate average training loss for the epoch\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)  # Store training loss\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)  # Forward pass\n",
    "            loss = criterion(outputs, batch_y)  # Compute validation loss\n",
    "            total_val_loss += loss.item()  # Accumulate validation loss\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "            correct += (predicted == batch_y).sum().item()  # Count correct predictions\n",
    "            total += batch_y.size(0)  # Total number of samples\n",
    "\n",
    "    # Calculate average validation loss and accuracy\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)  # Store validation loss\n",
    "    val_accuracy = correct / total  # Validation accuracy\n",
    "\n",
    "    # Print training and validation loss for the epoch\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/20], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy * 100:.2f}%\"\n",
    "    )\n",
    "\n",
    "# Print final training and validation losses\n",
    "print(\"\\nFinal Training Losses:\", train_losses)\n",
    "print(\"Final Validation Losses:\", val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"Model/RNN_Local_Context.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
